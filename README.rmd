Testing the iterative proportional fitting procedure
========

Introduction
----------
This project will test static spatial microsimulation models in a range of conditions. 
We will begin with IPF-based approaches, as these are simple, deterministic and readily available. 
The project is open access: all the code and data sets used to conduct the testing can be downloaded and modified. 
We encourage others to fork the entire project using the command `git clone` for testing on home computers. 
For people new to spatial microsimulation, there is an introductory tutorial avialable
[on RPubs](http://rpubs.com/RobinLovelace/5089) as well as a more involved tutorial using example code 
and data available from a paper hosted on [Elsevier](http://dx.doi.org/10.1016/j.compenvurbsys.2013.03.004) (as Supplementary data)
and [arXiv](http://arxiv.org/abs/1303.5228).

### Research problem
The research problem tackled is lack of rigorous and repeatable model evaluation and testing. Data and code used in published microsimulation research is not always publicly available. This can make it difficult for readers to reproduce results, test models in new ways and adapt the code for their own purposes. 

### Aim and objectives
The project aims to test each IPF model in a range of realistic conditions, changing only one parameter at a time. This will allow factors affecting IPF performance to be isolated and analysed.

Our objectives in creatng a framework for model evaluation are exactly the same as Holm and Malika's (2013) 'wish list', a set of principles that should be considered before developing new models:
* Using the most modern software
* Using standard methods, shared by many users 
* Backward compatibility (so keeping our old models and subsystems running) 
* Avoiding relearning 
* Developing solutions that are theoretically well designed 
* Transferring knowledge and know-how to new colleagues

### Input data
This data-driven approach requires a variety of input data sets. These will be grouped into scenarios that are designed to be realistic: simple to complex, small to large. The next stage is model preparation, which involves tailoring each to produce small area microdata in each of the scenarios. The final stage is testing: systematically altering specific aspects of each model to observe the factors affecting model performance.

Priorities
----------------
This is the current list of priorities, and will be updated as the project progresses:

* Discuss the modus operandi and structure of project
* Upload publicly available test data scenarios
* Add models, and modify them to generate spatial microdata for each scenario
* Run the models under a variety of scenarios, changing one parameter at a time. These parameters will include:
  * The initial weights
  * Number of iterations
  * Order of constraints
  * Integerisation
  * The use of cross-tabulated vs uni-variate categories (where available)
* Evaluate the results using quantitative methods

Modifying model runs
----------------------------

For systematic model experiments, only one variable in the model
set-up should be altered at a time.

To alter the number of iterations used in each model, one simply changes the
number in the following line of code (the default is 3) in the script files in
the 'models' folder:

```{r}
num.its <- 3
```

The code for running the constraints in a different order is saved in ‘etsim-reordered.R’. In this script file, the order in which constraints ran was systematically altered.

The code enabling weights to be altered is contained in the file
`etsim-weights.R`. The number of different initial weight runs can be controlled
by the parameter num.ws, which is set to 5 as an arbitrary default. Initial
weights are set to k, a vector of length num.ws which are by default set as a
function of u which is in term defined as the sequence `1:num.ws:k <- u/5 +
0.5`. In this case the
resultant weights are set to 0.7, 0.9, 1.1, 1.3 and 1.5 for each model
experiment. For factors of one million, for example, the above would be replaced
by `k <- u * 10^6`.

In a similar way, any of the input parameters in the models can be changed.
The variable changed in a specific script should be clear from its name.
'etsim-int*' script files, for example, demonstrate the impact of integerisation
on overall model performance.


<!--RMarkdown-->
<!--=======-->
<!--It is recommended that the initial analysis is written in RMarkdown language (as this introductory page is): it is lightweight, fast to type and, most importantly, allows R commands to be embedded and compiled within the text. For example, let us plot a simple polynomial:-->


<!--```r-->
<!--x = 1:10-->
<!--x2 = x^2 - 0.1 * x^3-->
<!--plot(x, x2)-->
<!--```-->

<!--![plot of chunk unnamed-chunk-1](figure/unnamed-chunk-1.png) -->





