# Reweighting the teaching file data
# Input objects generated by data-preparation.R:
# ind - the input microdata cons - the constraints

# Load the libraries we'll be using: install.packages("name-of-package") if not installed
library(ipfp) # for fast IPF
library(plyr) # for join function
library(dplyr) # for fast data manipulation
library(sfsmisc) # for real -> integer function

# Load the functions needed for reweighting:
source("functions.R")

# Data preparation
ind_agg <- cons # create aggregated estimated outputs (same dims and cons)
cons <- apply(cons, 2, as.numeric)
cons <- cons[1:4, ] # start with small version of the constraints - e.g. 1:10 for ten zones
ind_cat <- data.frame(ind_cat) # get ind_cat into right form

umat <- umat_count_dplyr(ind_cat) # create unique version of ind_cat
head(umat$u[1:5]) # check output
head(umat$u)
indu <- umat$u[-(1:2)]

# Input for ipfp
library(ipfp)
A <- t(indu) # the constraints
x0 <- rep(1, nrow(indu)) # the starting weights

i = 1 # testing for loop
w <- ipfp(cons[i, ], A, x0, maxit = 20) # ipfp on 1st constraint
summary(w)
weights <- w / umat$u$n # to go from per category to per person weights
weights <- weights[rep(1:nrow(umat$u), times = umat$u$n)] # final weights
cor(colSums(weights * ind_cat), cons[1, ])
ind_test <- indu[rep(row.names(umat$u), umat$u$n),] # we've returned full circle to the correct population
head(ind_test[1:10])
colSums(ind_test) - colSums(ind_cat) # getting the right results!

# Generate weights for all zones in cons
weights <- apply(cons, 1, function(x) ipfp(x, A, x0, maxit = 20))

# We get a better correlation after spatial microsim - only slightly due to tiny weights
summary(weights)
sum(weights)
iweights <- int_trs(weights[,1])
length(iweights)
colSums(ind_cat[iweights,])
cor(cons[1,], colSums(ind_cat[iweights,]))
cor(cons[1,], colSums(ind_cat)) # far better than pre-re-arrangement

# New method: loop to extract ind. indices from uniqe weights
iw <- roundfixS(weights) # convert weights to integer counts
index <- NULL
for(i in 1:nrow(umat$u)){
  sel <-  which(umat$p == umat$u$p[i])
  index <- c(index, sample(sel, size = iw[i], replace = TRUE))
}

ind_agg_test <- colSums(ind_cat[index, ])
cor(cons[1,], ind_agg_test) # very good fit
cor(cons[1,], colSums(ind_cat)) # new method is tested and working

# Generate final output using for loop over all zones - new method
ids <- as.list(rep(NA, nrow(cons)))
ind_agg <- NULL
for(j in 1:nrow(cons)){
  iw <- roundfixS(weights[,j])
  index <- NULL
  for(i in 1:nrow(umat$u)){
    sel <-  which(umat$p == umat$u$p[i])
    #   head(ind_cat[sel,1:7]) # test it works: remove
    index <- c(index, sample(sel, size = iw[i], replace = TRUE))
  }
  ids[[j]] <- index
  ind_agg <- rbind(ind_agg, colSums(ind_cat[index, ]))
}
plot(colSums(ind_agg), colSums(cons))
cor(as.numeric(as.matrix(ind_agg)), as.numeric(as.matrix(cons)))
# cor > 0.999: not bad

# The above is demonstrates a new way of using ipf to generate integer weights
# An alternative to 'TRS integerisation' more suitable for large datasets -
# possibly more accurate also

# Function to see how well the model matrix version fits reality
# fun <- function(par, ind_num, con){
#   sim <- colSums(par * ind_num)
#   ae <- abs(sim - con) # Absolute error per category
#   sum(ae) # the Total Absolute Error (TAE)
# }
# 
# fun(w, indu, cons[1,])
